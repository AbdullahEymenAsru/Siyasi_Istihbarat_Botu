import feedparser
import requests
import smtplib
import os
import glob
import datetime
import subprocess
import asyncio
import re
import networkx as nx
import matplotlib.pyplot as plt
import edge_tts
import trafilatura # <--- YENÄ° KÃœTÃœPHANE (TAM METÄ°N Ä°Ã‡Ä°N)
from groq import Groq
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.image import MIMEImage
from email import encoders

# ==========================================
# 1. AYARLAR
# ==========================================
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
GMAIL_USER = os.environ["GMAIL_USER"]
GMAIL_PASSWORD = os.environ["GMAIL_PASSWORD"]

raw_mail_list = os.environ["ALICI_MAIL"]
ALICI_LISTESI = [email.strip() for email in raw_mail_list.split(',')]

client = Groq(api_key=GROQ_API_KEY)
SES_MODELI = "tr-TR-AhmetNeural"
plt.switch_backend('Agg')

# KAYNAKLAR
rss_sources = {
    'BBC World': 'http://feeds.bbci.co.uk/news/world/rss.xml',
    'CNN International': 'http://rss.cnn.com/rss/edition.rss',
    'Voice of America (VOA)': 'https://www.voanews.com/api/zg$oq_et$p',
    'Foreign Policy': 'https://foreignpolicy.com/feed/',
    'Deutsche Welle': 'https://rss.dw.com/xml/rss-en-all',
    'TRT World': 'https://www.trtworld.com/rss',
    'Turkiye Arastirmalari Vakfi': 'https://tav.org.tr/feed/',
    'SETA Vakfi': 'https://www.setav.org/feed/',
    'Al Jazeera': 'https://www.aljazeera.com/xml/rss/all.xml',
    'Times of Israel': 'https://www.timesofisrael.com/feed/',
    'Tehran Times': 'https://www.tehrantimes.com/rss',
    'TASS (Russia)': 'https://tass.com/rss/v2.xml',
    'China Daily': 'https://www.chinadaily.com.cn/rss/world_rss.xml',
    'Yonhap (Korea)': 'https://en.yna.co.kr/RSS/news.xml',
    'Dawn (Pakistan)': 'https://www.dawn.com/feeds/home/',
    'Times of India': 'https://timesofindia.indiatimes.com/rssfeedstopstories.cms'
}

KRITIK_AKTORLER = ["Turkey", "TÃ¼rkiye", "ErdoÄŸan", "Fidan", "Biden", "Trump", "Putin", "Xi Jinping", "Zelensky", "Netanyahu", "Hamas", "NATO", "EU", "Iran", "China", "Russia", "Pakistan", "India", "Korea"]

# ==========================================
# 2. AJAN 1: RESEARCHER (VERÄ° TOPLAYICI & SCRAPER) ğŸ•·ï¸
# ==========================================
def calculate_priority_score(title, summary):
    score = 0
    text = (title + " " + summary).lower()
    
    high_priority = ["nuclear", "war", "missile", "attack", "gaza", "ukraine", "taiwan", "terror", "bomb", "sondakika"]
    if any(w in text for w in high_priority): score += 50
    
    med_priority = ["turkey", "erdogan", "nato", "putin", "biden", "trump", "iran", "israel", "defense", "military"]
    if any(w in text for w in med_priority): score += 30
    
    low_priority = ["trade", "economy", "deal", "meeting", "eu", "energy", "oil"]
    if any(w in text for w in low_priority): score += 10
    
    return score

def get_full_text(url):
    """Linke gider ve haberin tamamÄ±nÄ± indirir (Scraping)"""
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            text = trafilatura.extract(downloaded)
            if text:
                # Ã‡ok uzunsa kÄ±rp (Token limitini korumak iÃ§in)
                return text[:2500] 
    except:
        pass
    return None

def fetch_news():
    print("ğŸ•µï¸â€â™‚ï¸ AJAN 1: GeniÅŸletilmiÅŸ aÄŸ taranÄ±yor ve KRÄ°TÄ°K haberler okunuyor...")
    all_news = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # 1. ADIM: RSS TARAMA VE PUANLAMA
    for source, url in rss_sources.items():
        try:
            resp = requests.get(url, headers=headers, timeout=20)
            feed = feedparser.parse(resp.content)
            if feed.entries:
                for i, entry in enumerate(feed.entries[:3]):
                    title = entry.title
                    link = entry.link
                    summary = entry.summary[:200] if hasattr(entry, 'summary') else ""
                    
                    score = calculate_priority_score(title, summary)
                    if i == 0: score += 10 
                    
                    all_news.append({"source": source, "title": title, "link": link, "summary": summary, "score": score})
        except: continue

    # 2. ADIM: EN KRÄ°TÄ°K HABERLERÄ° SEÃ‡ME
    all_news.sort(key=lambda x: x['score'], reverse=True)
    top_news = all_news[:6] # En Ã¶nemli 6 haberi seÃ§
    
    buffer = ""
    raw_links_html = "<ul>"
    
    # 3. ADIM: SEÃ‡Ä°LENLER Ä°Ã‡Ä°N TAM METÄ°N Ä°NDÄ°RME (SCRAPING)
    print("ğŸ•·ï¸  AJAN 1: SeÃ§ilen haberlerin detaylarÄ±na iniliyor (Deep Dive)...")
    
    current_keywords = [] # HafÄ±za aramasÄ± iÃ§in anahtar kelimeler biriktiriyoruz

    for news in top_news:
        full_text = get_full_text(news['link'])
        
        # EÄŸer tam metin Ã§ekebildiysek onu kullan, yoksa Ã¶zeti kullan
        content_to_use = full_text if full_text else news['summary']
        content_type = "TAM METÄ°N" if full_text else "Ã–ZET"
        
        icon = "ğŸš¨" if news['score'] >= 50 else "ğŸ”¹"
        buffer += f"[{news['source']}] {icon} {news['title']} ({content_type})\nÄ°Ã‡ERÄ°K: {content_to_use[:1000]}...\nURL: {news['link']}\n\n"
        
        raw_links_html += f"<li><b>{news['source']}:</b> <a href='{news['link']}'>{news['title']}</a></li>"
        
        # BaÅŸlÄ±ktaki kelimeleri hafÄ±za iÃ§in sakla
        current_keywords.extend(news['title'].lower().split())
    
    raw_links_html += "</ul>"
    
    return buffer, raw_links_html, current_keywords

# ==========================================
# 3. AKILLI HAFIZA (CONTEXT-AWARE MEMORY) ğŸ§ 
# ==========================================
def read_historical_memory(current_keywords):
    print("ğŸ§  HAFIZA MODÃœLÃœ: GeÃ§miÅŸte bugÃ¼ne benzer olaylar aranÄ±yor...")
    
    memory_buffer = ""
    files = glob.glob("ARSIV/*.md")
    files.sort(key=os.path.getmtime, reverse=True)
    
    # Gereksiz kelimeleri temizle
    stop_words = ["the", "in", "at", "on", "for", "to", "and", "a", "of", "is", "with", "haber", "son", "dakika"]
    keywords = [k for k in current_keywords if len(k) > 4 and k not in stop_words]
    keywords = list(set(keywords))[:5] # En Ã¶nemli 5 kelime
    
    print(f"   -> Aranan Kavramlar: {keywords}")

    found_count = 0
    total_chars = 0
    SAFE_LIMIT = 12000 
    
    for file_path in files:
        if total_chars > SAFE_LIMIT: break
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            filename = os.path.basename(file_path)
            
            # RELEVANCE PUANI: Dosyada anahtar kelimeler geÃ§iyor mu?
            relevance = sum(content.lower().count(k) for k in keywords)
            
            # EÄŸer alakalÄ±ysa veya Ã§ok yeniyse (son 2 gÃ¼n) hafÄ±zaya al
            is_recent = (datetime.datetime.now() - datetime.datetime.fromtimestamp(os.path.getmtime(file_path))).days < 2
            
            if relevance > 0 or is_recent:
                # Ä°lgili kÄ±sÄ±mlarÄ± al (TamamÄ±nÄ± deÄŸil)
                short_content = content[:2000]
                memory_buffer += f"\n--- GEÃ‡MÄ°Å RAPOR ({filename}) [Alaka: {relevance}] ---\n{short_content}...\n"
                total_chars += len(short_content)
                found_count += 1
                
    if not memory_buffer: return "ArÅŸivde ilgili kayÄ±t bulunamadÄ±."
    print(f"   -> {found_count} adet ilgili geÃ§miÅŸ rapor bulundu.")
    return memory_buffer

# ==========================================
# 4. YENÄ°: YAPAY ZEKA TABANLI HARÄ°TA ğŸ—ºï¸ (AJAN 5)
# ==========================================
def draw_network_graph(text_data):
    print("ğŸ—ºï¸ AJAN 5: Ä°liÅŸkileri analiz edip harita Ã§iziyor...")
    
    prompt = f"""
    AÅŸaÄŸÄ±daki haber metnini analiz et ve Ã¼lkeler/liderler arasÄ±ndaki iliÅŸkileri Ã§Ä±kar.
    Sadece ÅŸu formatta Ã§Ä±ktÄ± ver: "AktÃ¶r1,AktÃ¶r2"
    Ã–rnek:
    USA,China
    Turkey,Greece
    Putin,Biden
    
    METÄ°N:
    {text_data[:4000]}
    """
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        relations = completion.choices[0].message.content.split('\n')
    except:
        relations = ["TÃ¼rkiye,DÃ¼nya"] 

    G = nx.Graph()
    for line in relations:
        if "," in line:
            parts = line.split(',')
            if len(parts) >= 2:
                source = parts[0].strip()
                target = parts[1].strip()
                if len(source) < 20 and len(target) < 20:
                    G.add_edge(source, target)
    
    if G.number_of_nodes() == 0: G.add_edge("TÃ¼rkiye", "KÃ¼resel Sistem")

    plt.figure(figsize=(12, 8))
    pos = nx.spring_layout(G, k=1.5) 
    nx.draw_networkx_nodes(G, pos, node_size=2500, node_color='#2c3e50', alpha=0.9)
    nx.draw_networkx_edges(G, pos, width=2, alpha=0.6, edge_color='#bdc3c7')
    nx.draw_networkx_labels(G, pos, font_size=9, font_color='white', font_weight='bold')
    plt.title("GÃœNLÃœK JEOPOLÄ°TÄ°K ETKÄ°LEÅÄ°M AÄI", fontsize=16, color='#c0392b')
    plt.axis('off')
    filename = "network_map.png"
    plt.savefig(filename, bbox_inches='tight', facecolor='#ecf0f1')
    plt.close()
    return filename

# ==========================================
# 5. AJANLI SÄ°MÃœLASYON
# ==========================================
def run_agent_workflow(current_data, historical_memory):
    
    print("â³ AJAN 2 (HISTORIAN): Ã‡alÄ±ÅŸÄ±yor...")
    historian_prompt = f"""
    Sen TarihÃ§isin. BugÃ¼nÃ¼n haberleri: {current_data[:5000]}
    GeÃ§miÅŸ (ArÅŸivden Bulunanlar): {historical_memory}
    GÃ¶revin: GeÃ§miÅŸteki benzer olaylarla bugÃ¼nÃ¼ kÄ±yasla. Trendleri yaz.
    """
    history_analysis = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[{"role": "user", "content": historian_prompt}]
    ).choices[0].message.content

    print("âš–ï¸ AJAN 3 (THE CRITIC): Ã‡alÄ±ÅŸÄ±yor...")
    critic_prompt = f"""
    Sen 'KÄ±zÄ±l TakÄ±m' liderisin. Veriler: {current_data[:5000]}
    BatÄ± ve DoÄŸu medyasÄ± arasÄ±ndaki farklarÄ± sertÃ§e eleÅŸtir.
    """
    critic_analysis = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[{"role": "user", "content": critic_prompt}]
    ).choices[0].message.content

    print("âœï¸ AJAN 4 (CHIEF EDITOR): Nihai rapor yazÄ±lÄ±yor...")
    
    final_system_prompt = """Sen SavaÅŸ OdasÄ± BaÅŸkanÄ±sÄ±n. NÄ°HAÄ° STRATEJÄ°K RAPORU yaz.
    
    KURALLAR:
    1. LÄ°NK ZORUNLU: OlaylarÄ±n yanÄ±na (<a href='URL'>Kaynak</a>) ekle.
    2. PROFESYONEL DÄ°L: "Realist Kanat" yerine "JEOPOLÄ°TÄ°K RÄ°SK ANALÄ°ZÄ°" gibi terimler kullan.
    
    BÃ–LÃœMLER:
    1. ğŸ”¥ JEOPOLÄ°TÄ°K RÄ°SK VE TEHDÄ°TLER (Eski Realist Kanat)
    2. ğŸ¤ DÄ°PLOMASÄ° VE EKONOMÄ°K FIRSATLAR (Eski Liberal Kanat)
    3. ğŸ‘ï¸ Ä°STÄ°HBARAT SAVAÅLARI (Propaganda Analizi)
    4. ğŸ“œ TARÄ°HSEL HAFIZA (ArÅŸiv Analizi)
    5. ğŸ‡¹ğŸ‡· ANKARA Ä°Ã‡Ä°N STRATEJÄ°K TAVSÄ°YE
    6. ğŸ² GELECEK SENARYOLARI (% OlasÄ±lÄ±klar)
    """
    
    final_user_prompt = f"""
    HAM VERÄ°LER (TAM METÄ°N Ä°Ã‡ERÄ°R): 
    {current_data[:7000]}
    
    TARÄ°HÃ‡Ä° VE DENETÃ‡Ä° NOTLARI: 
    {history_analysis}
    {critic_analysis}
    """
    
    final_report = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": final_system_prompt},
            {"role": "user", "content": final_user_prompt}
        ],
        temperature=0.5
    ).choices[0].message.content
    
    return final_report

# ==========================================
# 6. SES & MAÄ°L
# ==========================================
async def generate_voice(text, output_file):
    communicate = edge_tts.Communicate(text, SES_MODELI)
    await communicate.save(output_file)

def create_audio(text_content):
    print("ğŸ™ï¸ Seslendiriliyor...")
    clean_text = re.sub('<[^<]+?>', '', text_content)
    clean_text = re.sub(r'http\S+', '', clean_text)
    script = "SayÄ±n Konsey Ãœyeleri. KÃ¼resel Ä°stihbarat Raporu arz edilir. " + clean_text[:900]
    filename = "Gunluk_Brifing.mp3"
    try:
        asyncio.run(generate_voice(script, filename))
        return filename
    except: return None

def archive(report_body):
    date_str = datetime.datetime.now().strftime("%Y-%m-%d")
    path = f"ARSIV/WarRoom_{date_str}.md"
    if not os.path.exists("ARSIV"): os.makedirs("ARSIV")
    with open(path, "w", encoding="utf-8") as f: f.write(report_body)
    try:
        subprocess.run(["git", "config", "--global", "user.name", "WarRoom Bot"])
        subprocess.run(["git", "config", "--global", "user.email", "bot@github.com"])
        subprocess.run(["git", "add", path])
        subprocess.run(["git", "commit", "-m", f"SimÃ¼lasyon: {date_str}"])
        subprocess.run(["git", "push"])
    except: pass

def send_email_to_council(report_body, raw_links, audio_file, image_file):
    print(f"ğŸ“§ DaÄŸÄ±tÄ±m BaÅŸlÄ±yor: {len(ALICI_LISTESI)} KiÅŸi")
    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(GMAIL_USER, GMAIL_PASSWORD)
        
        for alici in ALICI_LISTESI:
            print(f"   -> GÃ¶nderiliyor: {alici}")
            msg = MIMEMultipart('related')
            msg['From'] = GMAIL_USER
            msg['To'] = alici 
            msg['Subject'] = f"ğŸ§  KÃœRESEL Ä°STÄ°HBARAT RAPORU - {datetime.date.today()}"
            msg_alternative = MIMEMultipart('alternative')
            msg.attach(msg_alternative)

            html_content = f"""
            <html><body style='font-family: Arial, sans-serif; color:#333;'>
                <h1 style="color:#2c3e50; text-align:center;">ğŸ›¡ï¸ SAVAÅ ODASI</h1>
                <p style="text-align:center;"><i>"BÃ¼yÃ¼k Veri Analizli Stratejik Rapor"</i></p>
                <hr>
                <center>
                    <h3>ğŸ•¸ï¸ GÃœNLÃœK ETKÄ°LEÅÄ°M AÄI</h3>
                    <img src="cid:network_map" style="width:100%; max-width:700px; border:1px solid #ddd; padding:5px; border-radius:10px;">
                    <p style="font-size:10px; color:gray;">(Yapay Zeka tarafÄ±ndan haberlerden otomatik Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r)</p>
                </center>
                <br>
                {report_body}
                <br><hr>
                <div style="font-size:12px; color:#555; background:#f9f9f9; padding:10px;">
                    <h3>ğŸ“š ANALÄ°Z EDÄ°LEN KAYNAKLAR</h3>
                    {raw_links}
                </div>
            </body></html>
            """
            msg_alternative.attach(MIMEText(html_content, 'html'))
            if image_file and os.path.exists(image_file):
                with open(image_file, 'rb') as f:
                    img = MIMEImage(f.read())
                    img.add_header('Content-ID', '<network_map>')
                    img.add_header('Content-Disposition', 'inline', filename=image_file)
                    msg.attach(img)
            if audio_file and os.path.exists(audio_file):
                with open(audio_file, "rb") as f:
                    part = MIMEBase('application', 'octet-stream')
                    part.set_payload(f.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', f'attachment; filename="{audio_file}"')
                msg.attach(part)
            
            server.sendmail(GMAIL_USER, alici, msg.as_string())
        server.quit()
        print("âœ… DaÄŸÄ±tÄ±m tamamlandÄ±!")
    except Exception as e:
        print(f"âŒ Hata: {e}")

if __name__ == "__main__":
    # 1. Haberleri Ã‡ek (Tam Metin Scraping ile) ve Anahtar Kelimeleri Al
    raw_data, raw_links, current_keywords = fetch_news()
    
    # 2. AkÄ±llÄ± HafÄ±zayÄ± Ã‡alÄ±ÅŸtÄ±r (BugÃ¼nÃ¼n kelimelerine gÃ¶re arÅŸiv tara)
    memory = read_historical_memory(current_keywords)
    
    if len(raw_data) > 20:
        report = run_agent_workflow(raw_data, memory)
        graph_map = draw_network_graph(raw_data)
        archive(report)
        audio = create_audio(report)
        send_email_to_council(report, raw_links, audio, graph_map)
    else:
        print("Veri yok.")

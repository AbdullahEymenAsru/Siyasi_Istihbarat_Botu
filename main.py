import feedparser
import requests
import smtplib
import os
import glob
import datetime
import time
import subprocess
import asyncio
import re
import networkx as nx
import matplotlib.pyplot as plt
import edge_tts
import trafilatura
from groq import Groq
from supabase import create_client, Client
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.image import MIMEImage
from email import encoders

# ==========================================
# 1. AYARLAR & GÃœVENLÄ°K
# ==========================================
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
GMAIL_USER = os.environ["GMAIL_USER"]
GMAIL_PASSWORD = os.environ["GMAIL_PASSWORD"]

# --- SUPABASE BAÄLANTISI ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ALICI LÄ°STESÄ°NÄ° VERÄ°TABANINDAN Ã‡EK (DÄ°NAMÄ°K)
def get_email_list():
    try:
        response = supabase.table("abone_listesi").select("email").eq("aktif", True).execute()
        emails = [row['email'] for row in response.data]
        if not emails:
            raw = os.environ.get("ALICI_MAIL", "")
            return [e.strip() for e in raw.split(',')] if raw else []
        return emails
    except Exception as e:
        print(f"VeritabanÄ± HatasÄ±: {e}")
        return []

ALICI_LISTESI = get_email_list()
# ----------------------------------

client = Groq(api_key=GROQ_API_KEY)
SES_MODELI = "tr-TR-AhmetNeural"
plt.switch_backend('Agg')

# --- KAYNAK HAVUZU ---
rss_sources = {
    'BBC World': 'http://feeds.bbci.co.uk/news/world/rss.xml',
    'Foreign Policy': 'https://foreignpolicy.com/feed/',
    'The Diplomat': 'https://thediplomat.com/feed/',
    'Stratfor': 'https://worldview.stratfor.com/rss/feed/all',
    'Al Jazeera': 'https://www.aljazeera.com/xml/rss/all.xml',
    'TASS (Russia)': 'https://tass.com/rss/v2.xml',
    'China Daily': 'https://www.chinadaily.com.cn/rss/world_rss.xml',
    'Tehran Times': 'https://www.tehrantimes.com/rss',
    'Times of Israel': 'https://www.timesofisrael.com/feed/',
    'ISW (War Study)': 'https://www.understandingwar.org/feeds.xml',
    'Carnegie Endowment': 'https://carnegieendowment.org/rss/solr/?fa=ir_search',
    'Clash Report': 'https://rsshub.app/telegram/channel/clashreport', 
    'Intel Slava': 'https://rsshub.app/telegram/channel/intelslava', 
    'Geopolitics Live': 'https://rsshub.app/telegram/channel/geopolitics_live', 
    'Bellincat': 'https://www.bellingcat.com/feed/' 
}

# ==========================================
# 2. AJAN 1: RESEARCHER
# ==========================================
def calculate_priority_score(title, summary):
    score = 0
    text = (title + " " + summary).lower()
    
    academic_keys = ["doctrine", "strategy", "hegemony", "nuclear", "geopolitics", "sanctions", "treaty", "alliance", "deterrence", "proxy war"]
    if any(w in text for w in academic_keys): score += 60
    
    conflict_keys = ["war", "attack", "missile", "gaza", "ukraine", "taiwan", "china", "russia", "nato", "turkey", "syria", "drone"]
    if any(w in text for w in conflict_keys): score += 40
    
    return score

def get_full_text(url):
    if "t.me" in url or "telegram" in url or ".pdf" in url: return None
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            text = trafilatura.extract(downloaded)
            if text: return text[:3000] 
    except: pass
    return None

def fetch_news():
    print("ğŸ•µï¸â€â™‚ï¸ AJAN 1: GeniÅŸ Ã§aplÄ± veri taramasÄ± yapÄ±lÄ±yor...")
    all_news = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    now = datetime.datetime.now()

    for source, url in rss_sources.items():
        try:
            resp = requests.get(url, headers=headers, timeout=20)
            feed = feedparser.parse(resp.content)
            if feed.entries:
                for entry in feed.entries[:6]: 
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        try:
                            pub_date = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
                            if (now - pub_date).total_seconds() > 86400:
                                continue 
                        except: pass 

                    title = entry.title
                    link = entry.link
                    summary = entry.summary[:400] if hasattr(entry, 'summary') else ""
                    score = calculate_priority_score(title, summary)
                    all_news.append({"source": source, "title": title, "link": link, "summary": summary, "score": score})
        except: continue

    all_news.sort(key=lambda x: x['score'], reverse=True)
    top_news = all_news[:12] 
    
    buffer = ""
    current_keywords = []

    print(f"ğŸ•·ï¸  AJAN 1: SeÃ§ilen {len(top_news)} GÃœNCEL haber iÅŸleniyor...")
    
    for i, news in enumerate(top_news):
        full_text = get_full_text(news['link']) if i < 5 else None
        content_to_use = full_text if full_text else news['summary']
        
        # Linkleri AI'a veriyoruz ki kendisi yerleÅŸtirsin
        buffer += f"--- HABER ID: {i+1} ---\nKAYNAK: {news['source']}\nURL: {news['link']}\nBAÅLIK: {news['title']}\nÄ°Ã‡ERÄ°K: {content_to_use[:1500]}\n\n"
        current_keywords.extend(news['title'].lower().split())
    
    return buffer, current_keywords

# ==========================================
# 3. HAFIZA
# ==========================================
def read_historical_memory(current_keywords):
    memory_buffer = ""
    files = glob.glob("ARSIV/*.md")
    files.sort(key=os.path.getmtime, reverse=True)
    keywords = list(set([k for k in current_keywords if len(k) > 5]))[:5]
    total_chars = 0
    for file_path in files:
        if total_chars > 10000: break
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if sum(content.lower().count(k) for k in keywords) > 0:
                memory_buffer += f"\n[GEÃ‡MÄ°Å RAPOR - {os.path.basename(file_path)}]: {content[:1500]}...\n"
                total_chars += len(content[:1500])
    return memory_buffer if memory_buffer else "ArÅŸivde doÄŸrudan iliÅŸkili Ã¶rÃ¼ntÃ¼ bulunamadÄ±."

# ==========================================
# 4. HARÄ°TA (AJAN 5)
# ==========================================
def draw_network_graph(text_data):
    print("ğŸ—ºï¸ AJAN 5: Ä°liÅŸki aÄŸÄ± Ã§iziliyor...")
    prompt = f"Metindeki 'Ãœlke-Ãœlke' veya 'Lider-Lider' gerilimlerini/ittifaklarÄ±nÄ± 'AktÃ¶r1,AktÃ¶r2' formatÄ±nda listele:\n{text_data[:4000]}"
    try:
        completion = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": prompt}], temperature=0.1)
        relations = completion.choices[0].message.content.split('\n')
    except: relations = [] 

    G = nx.Graph()
    for line in relations:
        if "," in line:
            parts = line.split(',')
            if len(parts) >= 2: G.add_edge(parts[0].strip(), parts[1].strip())
    if G.number_of_nodes() == 0: G.add_edge("Ankara", "DÃ¼nya")
    
    plt.figure(figsize=(10, 6))
    pos = nx.spring_layout(G, k=1.8) 
    nx.draw(G, pos, with_labels=True, node_color='#2c3e50', node_size=2200, font_color='white', font_size=8, font_weight='bold', edge_color='#95a5a6')
    
    filename = "network_map.png"
    plt.savefig(filename, bbox_inches='tight', dpi=100)
    plt.close()
    return filename

# ==========================================
# 5. AJANLI SÄ°MÃœLASYON (GELÄ°ÅMÄ°Å AKADEMÄ°K MOD)
# ==========================================
def run_agent_workflow(current_data, historical_memory):
    print("â³ AJAN 2 (TarihÃ§i) ve AJAN 3 (Teorisyen) Ã§alÄ±ÅŸÄ±yor...")
    critic_report = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[{"role": "user", "content": f"""
        Verilen metinlerdeki ({current_data[:5000]}) anlatÄ±larÄ± 'SÃ¶ylem Analizi' ile incele.
        BatÄ± ve DoÄŸu medyasÄ± arasÄ±ndaki Ã§eliÅŸkileri bul. YanÄ±tÄ± TÃ¼rkÃ§e ver.
        """}]
    ).choices[0].message.content

    print("âœï¸ AJAN 4 (BAÅ STRATEJÄ°ST): Rapor yazÄ±lÄ±yor...")
    
    # --- YENÄ°LENMÄ°Å PROMPT: ANALÄ°Z, LÄ°NKLER VE AKADEMÄ°K REFERANS ---
    final_system_prompt = """Sen SavaÅŸ OdasÄ±'nÄ±n BaÅŸ Stratejistisin. Hedef kitlen Siyaset Bilimi Ã¶ÄŸrencileri ve akademisyenler.
    
    GÃ–REVLERÄ°N:
    1. ANALÄ°Z: En kritik 3 olayÄ± 'Derin Analiz' ile incele (Teori + Pratik + Gelecek).
    2. UFUK TURU: Kalan haberleri SADECE listeleme. Her biri iÃ§in 1 cÃ¼mlelik 'Stratejik Ã–nem' analizi yap.
    3. LÄ°NKLEME: Her haberin veya analizin yanÄ±na mutlaka TIKLANABÄ°LÄ°R KAYNAK LÄ°NKÄ° koy. Format: (<a href='URL'>Kaynak</a>)
    4. REFERANS: Analiz yaparken kullandÄ±ÄŸÄ±n teorileri (Realizm, Liberalizm vb.) en alta 'Akademik Referanslar' baÅŸlÄ±ÄŸÄ±yla ekle.
    
    RAPOR ÅABLONU (HTML KULLAN - Streamlit iÃ§in renkleri zorla):
    <div style="background-color:#f4f6f7; color:#333333 !important; padding:15px; border-left:5px solid #c0392b; margin-bottom:20px;">
        <h2 style="color:#c0392b; margin-top:0;">âš¡ GÃœNÃœN STRATEJÄ°K Ã–ZETÄ°</h2>
        <p style="color:#333333 !important;"><i>(BÃ¼yÃ¼k resmi gÃ¶ren, vizyoner bir giriÅŸ paragrafÄ±.)</i></p>
    </div>

    <h3 style="color:#2c3e50;">1. ğŸ”­ DERÄ°N ANALÄ°Z: TEORÄ° VE PRATÄ°K</h3>
    <p style="color:#333333;"><b>Olay 1:</b> (BaÅŸlÄ±k) (<a href='URL'>Kaynak</a>)</p>
    <p style="color:#333333;"><b>Teorik Ã‡erÃ§eve:</b> (Ã–rn: "Mearsheimer'Ä±n Ofansif Realizmine gÃ¶re...")</p>
    <p style="color:#333333;"><b>Gelecek Projeksiyonu:</b> (Bu olay nereye evrilir?)</p>
    <br>
    <h3 style="color:#2980b9;">2. ğŸŒ KÃœRESEL UFUK TURU (Analitik Ã–zetler)</h3>
    <ul style="color:#333333;">
        <li>
            <b>(Ãœlke/Konu):</b> OlayÄ±n Ã¶zeti. 
            <i>Stratejik Ã–nem:</i> (Neden Ã¶nemli? 1 cÃ¼mle analiz). 
            (<a href='URL'>Kaynak</a>)
        </li>
        </ul>

    <h3 style="color:#d35400;">3. ğŸ‘ï¸ KIZIL TAKIM NOTLARI (Propaganda Analizi)</h3>
    <div style="font-size:14px; font-style:italic; color:#555555 !important;">{critic_report_placeholder}</div>

    <div style="background-color:#e8f8f5; color:#333333 !important; padding:15px; border-radius:5px; margin-top:20px; border:1px solid #1abc9c;">
        <h4 style="color:#16a085; margin-top:0;">ğŸ‡¹ğŸ‡· ANKARA Ä°Ã‡Ä°N POLÄ°TÄ°KA Ã–NERÄ°SÄ°</h4>
        <p style="color:#333333 !important;">(Realist bir perspektifle TÃ¼rkiye'ye somut tavsiye ver.)</p>
    </div>
    
    <br>
    <div style="background-color:#fffcf5; border:1px solid #ddd; padding:15px; margin-top:20px; color:#333333 !important;">
        <h4 style="color:#856404; margin-top:0;">ğŸ“š KULLANILAN AKADEMÄ°K REFERANSLAR</h4>
        <ul style="font-size:12px; color:#555;">
            <li>(Analizinde kullandÄ±ÄŸÄ±n teorilere ait kitap/makale kÃ¼nyelerini buraya ekle. Ã–rn: Waltz, Kenneth N. Theory of International Politics.)</li>
        </ul>
    </div>
    """
    
    final_user_prompt = f"""
    HAM VERÄ°LER (URL'ler dahil): 
    {current_data[:15000]}
    
    TARÄ°HSEL BAÄLAM: {historical_memory}
    ELEÅTÄ°REL ANALÄ°Z: {critic_report}
    
    YukarÄ±daki ÅŸablona tam uyarak raporu yaz. 
    Her haberin yanÄ±na URL'sini <a href='...'></a> ÅŸeklinde gÃ¶mmeyi UNUTMA.
    Åablondaki {{critic_report_placeholder}} yerine eleÅŸtirel analizi Ã¶zetleyerek koy.
    """
    
    final_report = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": final_system_prompt.replace("{critic_report_placeholder}", "AÅŸaÄŸÄ±da detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.")},
            {"role": "user", "content": final_user_prompt}
        ],
        temperature=0.3
    ).choices[0].message.content
    return final_report

# ==========================================
# 6. SES & MAÄ°L & ARÅÄ°V
# ==========================================
async def generate_voice(text, output_file):
    communicate = edge_tts.Communicate(text, SES_MODELI)
    await communicate.save(output_file)

def create_audio(text_content):
    print("ğŸ™ï¸ Seslendiriliyor...")
    clean_text = re.sub('<[^<]+?>', '', text_content)
    clean_text = re.sub(r'http\S+', '', clean_text)
    script = "SavaÅŸ OdasÄ± GÃ¼nlÃ¼k Ä°stihbarat Raporu. " + clean_text[:1500]
    filename = "Analiz_Ozet.mp3"
    try:
        asyncio.run(generate_voice(script, filename))
        return filename
    except: return None

def archive(report_body):
    date_str = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M")
    path = f"ARSIV/Analiz_{date_str}.md"
    if not os.path.exists("ARSIV"): os.makedirs("ARSIV")
    # AI artÄ±k kaynakÃ§ayÄ± iÃ§ine gÃ¶mÃ¼yor, o yÃ¼zden direkt kaydediyoruz
    with open(path, "w", encoding="utf-8") as f: f.write(report_body)
    try:
        subprocess.run(["git", "config", "--global", "user.name", "WarRoom Bot"])
        subprocess.run(["git", "config", "--global", "user.email", "bot@github.com"])
        subprocess.run(["git", "add", path])
        subprocess.run(["git", "commit", "-m", f"Rapor: {date_str}"])
        subprocess.run(["git", "push"])
    except: pass

def send_email_to_council(report_body, audio_file, image_file):
    if not ALICI_LISTESI:
        print("âŒ HATA: GÃ¶nderilecek mail adresi bulunamadÄ±!")
        return

    print(f"ğŸ“§ GÃ¶nderiliyor: {len(ALICI_LISTESI)} kiÅŸi")
    CANLI_DASHBOARD_LINKI = "https://siyasi-istihbarat-botu.streamlit.app" 
    
    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(GMAIL_USER, GMAIL_PASSWORD)
        
        for alici in ALICI_LISTESI:
            msg = MIMEMultipart('related')
            msg['From'] = GMAIL_USER
            msg['To'] = alici 
            msg['Subject'] = f"ğŸ§  SAVAÅ ODASI: Stratejik Derinlik - {datetime.date.today()}"
            msg_alternative = MIMEMultipart('alternative')
            msg.attach(msg_alternative)

            # --- GÃœNCELLENMÄ°Å MAÄ°L TASARIMI (Buton Tepede) ---
            html_content = f"""
            <html><body style='font-family: "Georgia", serif; color:#222; line-height: 1.6; background-color: #f9f9f9; padding: 20px;'>
                <div style="max-width: 800px; margin: auto; background: white; padding: 40px; border-radius: 5px; box-shadow: 0 0 15px rgba(0,0,0,0.05); border-top: 5px solid #c0392b;">
                    
                    <div style="text-align: center; margin-bottom: 20px;">
                        <h1 style="color:#2c3e50; font-family: 'Impact', sans-serif; letter-spacing: 1px; margin-bottom: 5px;">SAVAÅ ODASI</h1>
                        <p style="color:#7f8c8d; font-style: italic; margin-top: 0;">"Derinlik, GeniÅŸlik ve Strateji"</p>
                    </div>

                    <div style="text-align:center; margin: 30px 0;">
                        <a href="{CANLI_DASHBOARD_LINKI}" style="background-color: #c0392b; color: #ffffff; padding: 16px 24px; text-decoration: none; border-radius: 6px; font-weight: bold; font-size: 16px; font-family: sans-serif; display: inline-block; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
                           ğŸš€ CANLI Ä°STÄ°HBARAT MASASINA BAÄLAN
                        </a>
                    </div>
                    <div style="text-align:center; margin-bottom:20px;">
                         <img src="cid:network_map" style="width:100%; max-width:700px; border: 1px solid #ddd; padding: 5px;">
                         <p style="font-size:12px; color:#999;">GÃ¼nlÃ¼k Ä°liÅŸki AÄŸÄ±</p>
                    </div>

                    <div style="font-size: 16px;">{report_body}</div>
                    
                    <div style="margin-top: 30px; text-align: center; font-size: 12px; color: #999;">
                        Bu rapor Yapay Zeka destekli OSINT verileriyle oluÅŸturulmuÅŸtur.
                    </div>
                </div>
            </body></html>
            """
            msg_alternative.attach(MIMEText(html_content, 'html'))
            
            if image_file and os.path.exists(image_file):
                with open(image_file, 'rb') as f:
                    img = MIMEImage(f.read())
                    img.add_header('Content-ID', '<network_map>')
                    img.add_header('Content-Disposition', 'inline', filename=image_file)
                    msg.attach(img)
            
            if audio_file and os.path.exists(audio_file):
                with open(audio_file, "rb") as f:
                    part = MIMEBase('application', 'octet-stream')
                    part.set_payload(f.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', f'attachment; filename="{audio_file}"')
                msg.attach(part)
            
            server.sendmail(GMAIL_USER, alici, msg.as_string())
        server.quit()
        print("âœ… Rapor baÅŸarÄ±yla daÄŸÄ±tÄ±ldÄ±.")
    except Exception as e:
        print(f"âŒ Mail HatasÄ±: {e}")

if __name__ == "__main__":
    # raw_links deÄŸiÅŸkenini kaldÄ±rdÄ±k Ã§Ã¼nkÃ¼ linkler artÄ±k AI metninin iÃ§inde gÃ¶mÃ¼lÃ¼
    raw_data, current_keywords = fetch_news() 
    memory = read_historical_memory(current_keywords)
    if len(raw_data) > 50: 
        report = run_agent_workflow(raw_data, memory)
        graph_map = draw_network_graph(raw_data)
        
        # Raporun tamamÄ±nÄ± (KaynakÃ§a dahil) arÅŸivliyoruz
        archive(report)
        
        audio = create_audio(report)
        send_email_to_council(report, audio, graph_map)
    else:
        print("Yeterli veri yok, rapor oluÅŸturulmadÄ±.")
